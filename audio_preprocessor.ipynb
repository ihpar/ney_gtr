{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from constants import *\n",
    "import IPython.display as ipd\n",
    "from disk_utils import load_model\n",
    "from pathlib import Path, PurePath\n",
    "from plotter import plot_loss, plot_heatmaps, plot_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTR_AUDIO_FEATURES_DIR = \"dataset/audio_features/gtr/\"\n",
    "NEY_AUDIO_FEATURES_DIR = \"dataset/audio_features/ney/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_feature_paths = sorted([f_dir for f_dir in Path(\n",
    "    GTR_FEATURE_DIR).iterdir() if f_dir.is_dir()])\n",
    "\n",
    "ney_feature_paths = sorted([f_dir for f_dir in Path(\n",
    "    NEY_FEATURE_DIR).iterdir() if f_dir.is_dir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/features/min_max.pkl\", \"rb\") as handle:\n",
    "    min_max = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(\"generator_sp_32_0_8_full\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/features/gtr/Gtr_1_01 done!\n",
      "dataset/features/gtr/Gtr_1_02 done!\n",
      "dataset/features/gtr/Gtr_1_03 done!\n",
      "dataset/features/gtr/Gtr_1_04 done!\n",
      "dataset/features/gtr/Gtr_1_05 done!\n",
      "dataset/features/gtr/Gtr_1_06 done!\n",
      "dataset/features/gtr/Gtr_1_07 done!\n",
      "dataset/features/gtr/Gtr_1_08 done!\n",
      "dataset/features/gtr/Gtr_1_09 done!\n",
      "dataset/features/gtr/Gtr_1_10 done!\n",
      "dataset/features/gtr/Gtr_1_11 done!\n",
      "dataset/features/gtr/Gtr_1_12 done!\n",
      "dataset/features/gtr/Gtr_1_13 done!\n",
      "dataset/features/gtr/Gtr_1_14 done!\n",
      "dataset/features/gtr/Gtr_1_15 done!\n",
      "dataset/features/gtr/Gtr_1_16 done!\n",
      "dataset/features/gtr/Gtr_1_17 done!\n",
      "dataset/features/gtr/Gtr_1_18 done!\n",
      "dataset/features/gtr/Gtr_1_19 done!\n",
      "dataset/features/gtr/Gtr_1_20 done!\n",
      "dataset/features/gtr/Gtr_1_21 done!\n",
      "dataset/features/gtr/Gtr_1_22 done!\n",
      "dataset/features/gtr/Gtr_1_23 done!\n",
      "dataset/features/gtr/Gtr_1_24 done!\n",
      "dataset/features/gtr/Gtr_1_25 done!\n",
      "dataset/features/gtr/Gtr_1_26 done!\n",
      "dataset/features/gtr/Gtr_1_27 done!\n",
      "dataset/features/gtr/Gtr_1_28 done!\n",
      "dataset/features/gtr/Gtr_1_29 done!\n",
      "dataset/features/gtr/Gtr_1_30 done!\n",
      "dataset/features/gtr/Gtr_2_01 done!\n",
      "dataset/features/gtr/Gtr_2_02 done!\n",
      "dataset/features/gtr/Gtr_2_03 done!\n",
      "dataset/features/gtr/Gtr_2_04 done!\n",
      "dataset/features/gtr/Gtr_2_05 done!\n",
      "dataset/features/gtr/Gtr_2_06 done!\n",
      "dataset/features/gtr/Gtr_2_07 done!\n",
      "dataset/features/gtr/Gtr_2_08 done!\n",
      "dataset/features/gtr/Gtr_2_09 done!\n",
      "dataset/features/gtr/Gtr_2_10 done!\n",
      "dataset/features/gtr/Gtr_2_11 done!\n",
      "dataset/features/gtr/Gtr_2_12 done!\n",
      "dataset/features/gtr/Gtr_2_13 done!\n",
      "dataset/features/gtr/Gtr_2_14 done!\n",
      "dataset/features/gtr/Gtr_2_15 done!\n",
      "dataset/features/gtr/Gtr_2_16 done!\n",
      "dataset/features/gtr/Gtr_2_17 done!\n",
      "dataset/features/gtr/Gtr_2_18 done!\n",
      "dataset/features/gtr/Gtr_2_19 done!\n",
      "dataset/features/gtr/Gtr_2_20 done!\n",
      "dataset/features/gtr/Gtr_2_21 done!\n",
      "dataset/features/gtr/Gtr_2_22 done!\n",
      "dataset/features/gtr/Gtr_2_23 done!\n",
      "dataset/features/gtr/Gtr_2_24 done!\n",
      "dataset/features/gtr/Gtr_2_25 done!\n",
      "dataset/features/gtr/Gtr_2_26 done!\n",
      "dataset/features/gtr/Gtr_2_27 done!\n",
      "dataset/features/gtr/Gtr_2_28 done!\n",
      "dataset/features/gtr/Gtr_2_29 done!\n",
      "dataset/features/gtr/Gtr_2_30 done!\n"
     ]
    }
   ],
   "source": [
    "num_dirs = len(gtr_feature_paths)\n",
    "AUDIO_DIR = \"dataset/audio_features/\"\n",
    "\n",
    "for i, (gtr_fp, ney_fp) in enumerate(zip(gtr_feature_paths, ney_feature_paths)):\n",
    "    gtr_files = sorted([f.name for f in gtr_fp.iterdir() if f.name.startswith(\n",
    "        \"chunk\")], key=lambda x: int(x.split(\"_\")[1]))\n",
    "    ney_files = sorted([f.name for f in ney_fp.iterdir() if f.name.startswith(\n",
    "        \"chunk\")], key=lambda x: int(x.split(\"_\")[1]))\n",
    "    for j, (gtr_file, ney_file) in enumerate(zip(gtr_files, ney_files)):\n",
    "        gtr_path = str(gtr_fp) + \"/\" + gtr_file\n",
    "        ney_path = str(ney_fp) + \"/\" + ney_file\n",
    "\n",
    "        with open(gtr_path, \"rb\") as handle:\n",
    "            gtr_chunk = pickle.load(handle)\n",
    "\n",
    "        with open(ney_path, \"rb\") as handle:\n",
    "            ney_chunk = pickle.load(handle)\n",
    "\n",
    "        gtr_phase = gtr_chunk[\"phase\"]\n",
    "        gtr_db = gtr_chunk[\"db\"]\n",
    "        # 0 - 1 scale\n",
    "        gtr_db = (gtr_db - min_max[\"gtr\"][\"min\"][\"db\"]) / \\\n",
    "            (min_max[\"gtr\"][\"max\"][\"db\"] - min_max[\"gtr\"][\"min\"][\"db\"])\n",
    "        gtr_db = np.expand_dims(gtr_db, axis=0)\n",
    "        with torch.no_grad():\n",
    "            gtr_db = torch.from_numpy(\n",
    "                np.array([gtr_db], dtype=np.float32)).to(device)\n",
    "            predicted_db = model(gtr_db)[0]\n",
    "            predicted_db = predicted_db.to(\n",
    "                torch.device(\"cpu\")).numpy().squeeze(axis=0)\n",
    "        \n",
    "        # un-scale\n",
    "        predicted_db = predicted_db * \\\n",
    "            (min_max[\"ney\"][\"max\"][\"db\"] - min_max[\"ney\"][\"min\"][\"db\"]) + \\\n",
    "            min_max[\"ney\"][\"min\"][\"db\"]\n",
    "        \n",
    "        # back to magnitude\n",
    "        predicted_db = librosa.db_to_amplitude(predicted_db)\n",
    "        \n",
    "        # reconstruct predicted signal\n",
    "        pred_signal = librosa.istft(predicted_db * np.exp(1j * gtr_phase),\n",
    "                                    n_fft=N_FFT, hop_length=HOP)\n",
    "        \n",
    "        # overload protection\n",
    "        signal_max = np.max(np.abs(pred_signal))\n",
    "        if signal_max > 1.0:\n",
    "            pred_signal = pred_signal / signal_max\n",
    "\n",
    "        # write wave files\n",
    "        idx = i * num_dirs + j\n",
    "        file_trail = f\"{idx:03d}.wav\"\n",
    "        sf.write(AUDIO_DIR + \"gtr/gtr_\" + file_trail,\n",
    "                 pred_signal, SR, format=\"wav\")\n",
    "        ney_signal = ney_chunk[\"signal\"]\n",
    "        sf.write(AUDIO_DIR + \"ney/ney_\" + file_trail,\n",
    "                 ney_signal, SR, format=\"wav\")\n",
    "\n",
    "    print(str(gtr_fp), \"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
